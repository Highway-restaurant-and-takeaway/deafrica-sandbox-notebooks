{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook for testing code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import datacube\n",
    "import numpy as np\n",
    "import sys\n",
    "import xarray as xr\n",
    "from datacube.utils.dask import start_local_dask\n",
    "\n",
    "\n",
    "import dask\n",
    "from odc.algo._dask import reshape_yxbt\n",
    "import dask.array as da\n",
    "from odc.algo import randomize, reshape_for_geomedian\n",
    "from datacube.utils.geometry import assign_crs\n",
    "\n",
    "from odc.algo import yxbt_sink\n",
    "import hdstats\n",
    "\n",
    "sys.path.append('../Scripts')\n",
    "from deafrica_datahandling import load_ard\n",
    "from deafrica_dask import create_local_dask_cluster\n",
    "from deafrica_plotting import rgb\n",
    "from datacube.testutils.io import rio_slurp_xarray\n",
    "from odc.algo._dask import reshape_yxbt\n",
    "import psutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --extra-index-url=https://packages.dea.ga.gov.au/ hdstats==0.1.8post1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client = create_local_dask_cluster()\n",
    "ncpu = psutil.cpu_count() - 2\n",
    "client = start_local_dask(nanny=False,\n",
    "                          n_workers=1, threads_per_worker=ncpu, mem_safety_margin='6G', # Generic\n",
    "                          processes=False)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = datacube.Datacube(app='stuff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define area of interest\n",
    "lat = -3.0475\n",
    "lon = 37.322\n",
    "lon_buffer = 0.1\n",
    "lat_buffer = 0.1\n",
    "\n",
    "# Combine central lat,lon with buffer to get area of interest\n",
    "lat_range = (lat-lat_buffer, lat+lat_buffer)\n",
    "lon_range = (lon-lon_buffer, lon+lon_buffer)\n",
    "\n",
    "# Set the range of dates for the analysis\n",
    "years_range = ('2019-01', '2019-12')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a reusable query\n",
    "query = {\n",
    "    'y': lat_range,\n",
    "    'x': lon_range,\n",
    "    'time': years_range,\n",
    "    'measurements': ['red','blue','green','nir','swir_1',\n",
    "                     'swir_2','red_edge_1','red_edge_2','red_edge_3'],\n",
    "    'resolution': (-10,10),\n",
    "    'output_crs': 'epsg:6933',\n",
    "    'group_by': 'solar_day'\n",
    "}\n",
    "\n",
    "# Load available data from Landsat 8\n",
    "ds = load_ard(dc=dc,\n",
    "              products=['s2_l2a'],\n",
    "              **query,\n",
    "#               dtype='native',\n",
    "              dask_chunks={},\n",
    "              scaling='normalised'\n",
    "              )\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xr_geomedian_tmad(ds, axis='time', where=None, **kw):\n",
    "    \"\"\"\n",
    "    :param ds: xr.Dataset|xr.DataArray|numpy array\n",
    "    Other parameters:\n",
    "    **kwargs -- passed on to pcm.gnmpcm\n",
    "       maxiters   : int         1000\n",
    "       eps        : float       0.0001\n",
    "       num_threads: int| None   None\n",
    "    \"\"\"\n",
    "\n",
    "    import hdstats\n",
    "    def gm_tmad(arr, **kw):\n",
    "        \"\"\"\n",
    "        arr: a high dimensional numpy array where the last dimension will be reduced. \n",
    "    \n",
    "        returns: a numpy array with one less dimension than input.\n",
    "        \"\"\"\n",
    "        gm = hdstats.nangeomedian_pcm(arr, **kw)\n",
    "        return gm\n",
    "#         nt = kw.pop('num_threads', None)\n",
    "#         emad = hdstats.emad_pcm(arr, gm, num_threads=nt)[:,:, np.newaxis]\n",
    "#         smad = hdstats.smad_pcm(arr, gm, num_threads=nt)[:,:, np.newaxis]\n",
    "#         bcmad = hdstats.bcmad_pcm(arr, gm, num_threads=nt)[:,:, np.newaxis]\n",
    "#         return np.concatenate([gm, emad, smad, bcmad], axis=-1)\n",
    "\n",
    "\n",
    "    def norm_input(ds, axis):\n",
    "        if isinstance(ds, xr.DataArray):\n",
    "            xx = ds\n",
    "            if len(xx.dims) != 4:\n",
    "                raise ValueError(\"Expect 4 dimensions on input: y,x,band,time\")\n",
    "            if axis is not None and xx.dims[3] != axis:\n",
    "                raise ValueError(f\"Can only reduce last dimension, expect: y,x,band,{axis}\")\n",
    "            return None, xx, xx.data\n",
    "        elif isinstance(ds, xr.Dataset):\n",
    "            xx = reshape_for_geomedian(ds, axis)\n",
    "            return ds, xx, xx.data\n",
    "        else:  # assume numpy or similar\n",
    "            xx_data = ds\n",
    "            if xx_data.ndim != 4:\n",
    "                raise ValueError(\"Expect 4 dimensions on input: y,x,band,time\")\n",
    "            return None, None, xx_data\n",
    "\n",
    "    kw.setdefault('nocheck', False)\n",
    "    kw.setdefault('num_threads', 1)\n",
    "    kw.setdefault('eps', 1e-6)\n",
    "\n",
    "    ds, xx, xx_data = norm_input(ds, axis)\n",
    "    is_dask = dask.is_dask_collection(xx_data)\n",
    "\n",
    "    if where is not None:\n",
    "        if is_dask:\n",
    "            raise NotImplementedError(\"Dask version doesn't support output masking currently\")\n",
    "\n",
    "        if where.shape != xx_data.shape[:2]:\n",
    "            raise ValueError(\"Shape for `where` parameter doesn't match\")\n",
    "        set_nan = ~where\n",
    "    else:\n",
    "        set_nan = None\n",
    "\n",
    "    if is_dask:\n",
    "        if xx_data.shape[-2:] != xx_data.chunksize[-2:]:\n",
    "            xx_data = xx_data.rechunk(xx_data.chunksize[:2] + (-1, -1))\n",
    "\n",
    "        data = da.map_blocks(lambda x: gm_tmad(x, **kw),\n",
    "                             xx_data,\n",
    "                             name=randomize('geomedian'),\n",
    "                             dtype=xx_data.dtype, \n",
    "                             chunks=xx_data.chunks[:-2] + (xx_data.chunks[-2][0]+3,),\n",
    "                             drop_axis=3)\n",
    "    else:\n",
    "        data = gm_tmad(xx_data, **kw)\n",
    "    return data\n",
    "#     if set_nan is not None:\n",
    "#         data[set_nan, :] = np.nan\n",
    "\n",
    "#     if xx is None:\n",
    "#         return data\n",
    "\n",
    "#     dims = xx.dims[:-1]\n",
    "#     cc = {k: xx.coords[k] for k in dims}\n",
    "#     cc[dims[-1]] = np.hstack([xx.coords[dims[-1]].values,['edev', 'sdev', 'bcdev']])\n",
    "#     xx_out = xr.DataArray(data, dims=dims, coords=cc)\n",
    "\n",
    "#     if ds is None:\n",
    "#         xx_out.attrs.update(xx.attrs)\n",
    "#         return xx_out\n",
    "\n",
    "#     ds_out = xx_out.to_dataset(dim='band')\n",
    "#     for b in ds.data_vars.keys():\n",
    "#         src, dst = ds[b], ds_out[b]\n",
    "#         dst.attrs.update(src.attrs)\n",
    "\n",
    "#     return assign_crs(ds_out, crs=ds.geobox.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old=xr_geomedian_tmad(ds.chunk({'x':1500, 'y':1500, 'time':1}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "old=old.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old\n",
    "# old gm+tmads: 7min 51s\n",
    "# old gm-only: 7min 20s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xr_geomedian_tmad_new(ds, axis='time', **kw):\n",
    "    \"\"\"\n",
    "    :param ds: xr.Dataset|xr.DataArray|numpy array\n",
    "    Other parameters:\n",
    "    **kwargs -- passed on to pcm.gnmpcm\n",
    "       maxiters   : int         1000\n",
    "       eps        : float       0.0001\n",
    "       num_threads: int| None   None\n",
    "    \"\"\"\n",
    "\n",
    "    import hdstats\n",
    "    def gm_tmad(arr, **kw):\n",
    "        \"\"\"\n",
    "        arr: a high dimensional numpy array where the last dimension will be reduced. \n",
    "    \n",
    "        returns: a numpy array with one less dimension than input.\n",
    "        \"\"\"\n",
    "        gm = hdstats.nangeomedian_pcm(arr, **kw)\n",
    "        return gm\n",
    "#         nt = kw.pop('num_threads', None)\n",
    "#         emad = hdstats.emad_pcm(arr, gm, num_threads=nt)[:,:, np.newaxis]\n",
    "#         smad = hdstats.smad_pcm(arr, gm, num_threads=nt)[:,:, np.newaxis]\n",
    "#         bcmad = hdstats.bcmad_pcm(arr, gm, num_threads=nt)[:,:, np.newaxis]\n",
    "#         return np.concatenate([gm, emad, smad, bcmad], axis=-1)\n",
    "\n",
    "\n",
    "    def norm_input(ds):\n",
    "        if isinstance(ds, xr.Dataset):\n",
    "            xx = reshape_yxbt(ds, yx_chunks=500)\n",
    "            return ds, xx, xx.data\n",
    "\n",
    "    kw.setdefault('nocheck', False)\n",
    "    kw.setdefault('num_threads', 1)\n",
    "    kw.setdefault('eps', 1e-6)\n",
    "\n",
    "    ds, xx, xx_data = norm_input(ds)\n",
    "    is_dask = dask.is_dask_collection(xx_data)\n",
    "\n",
    "    if is_dask:\n",
    "        data = da.map_blocks(lambda x: gm_tmad(x, **kw),\n",
    "                             xx_data,\n",
    "                             name=randomize('geomedian'),\n",
    "                             dtype=xx_data.dtype, \n",
    "                             chunks=xx_data.chunks[:-2] + (xx_data.chunks[-2][0]+3,),\n",
    "                             drop_axis=3)\n",
    "    return data\n",
    "#     dims = xx.dims[:-1]\n",
    "#     cc = {k: xx.coords[k] for k in dims}\n",
    "#     cc[dims[-1]] = np.hstack([xx.coords[dims[-1]].values,['edev', 'sdev', 'bcdev']])\n",
    "#     xx_out = xr.DataArray(data, dims=dims, coords=cc)\n",
    "\n",
    "#     if ds is None:\n",
    "#         xx_out.attrs.update(xx.attrs)\n",
    "#         return xx_out\n",
    "\n",
    "#     ds_out = xx_out.to_dataset(dim='band')\n",
    "#     for b in ds.data_vars.keys():\n",
    "#         src, dst = ds[b], ds_out[b]\n",
    "#         dst.attrs.update(src.attrs)\n",
    "\n",
    "#     return assign_crs(ds_out, crs=ds.geobox.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new=xr_geomedian_tmad_new(ds.chunk({'x':11000, 'y':11000, 'time':1}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "new=new.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new\n",
    "# new gm+tmads: 6min 35s\n",
    "# new gm-only: 7min 57s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunk=750, no persist 4min 30s\n",
    "# chunk=750, persist 4min 21s\n",
    "# chunk=500, persist 5min 48s\n",
    "\n",
    "# no_dask = 3min 50s\n",
    "# no_dask_sink = 2min 55s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# no-dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dask.config.config['distributed']['worker']['memory']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xr_geomedian_tmad_fast(ds, ncpu, client):\n",
    "    \"\"\"\n",
    "    Fastest version of geomedian+TMADS.\n",
    "    Dask is used to arrange data into yxbt order,\n",
    "    openmp runs runs gm+tmads in parallel, but all\n",
    "    data is stored in memory\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    def gm_tmad(arr, ncpu, **kw):\n",
    "        \"\"\"\n",
    "        arr: a high dimensional numpy array where the last dimension will be reduced. \n",
    "    \n",
    "        returns: a numpy array with one less dimension than input.\n",
    "        \"\"\"\n",
    "        print('gm')\n",
    "        gm = hdstats.nangeomedian_pcm(arr, maxiters=1000,\n",
    "                                   eps=1e-4,\n",
    "                                   nocheck=True, \n",
    "                                   nodata=0,\n",
    "                                   num_threads=ncpu)\n",
    "        print('tmads')\n",
    "        emad = hdstats.emad_pcm(arr, gm, num_threads=ncpu)[:,:, np.newaxis]\n",
    "        smad = hdstats.smad_pcm(arr, gm, num_threads=ncpu)[:,:, np.newaxis]\n",
    "        bcmad = hdstats.bcmad_pcm(arr, gm, num_threads=ncpu)[:,:, np.newaxis]\n",
    "        return np.concatenate([gm, emad, smad, bcmad], axis=-1)\n",
    "    \n",
    "    # reorder data into yxbt order using dask\n",
    "    bands = list(dv.data for dv in ds.data_vars.values())\n",
    "    xx_data = yxbt_sink(bands, client)\n",
    "    \n",
    "    # run the gm and tmads using hdstats \n",
    "    data = gm_tmad(xx_data, ncpu)\n",
    "\n",
    "    # recreate xarray\n",
    "    dims = ('y', 'x', 'band')\n",
    "    cc = ds.geobox.xr_coords(with_crs=True)\n",
    "    cc['band'] = list(ds.data_vars)\n",
    "    cc[dims[-1]] = np.hstack([cc[dims[-1]], ['edev', 'sdev', 'bcdev']])\n",
    "    xx_out = xr.DataArray(data, dims=dims, coords=cc)\n",
    "\n",
    "    ds_out = xx_out.to_dataset(dim='band')\n",
    "    for b in ds.data_vars.keys():\n",
    "        src, dst = ds[b], ds_out[b]\n",
    "        dst.attrs.update(src.attrs)\n",
    "\n",
    "    return assign_crs(ds_out, crs=ds.geobox.crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "nodask=xr_geomedian_tmad_fast(ds, ncpu=ncpu, client=client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nodask\n",
    "# nodask gm+tmads 18mins 14s\n",
    "# nodask gm-only 5min 43s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodask['edev'] = -np.log(nodask['edev'])\n",
    "nodask['sdev'] = -np.log(nodask['sdev'])\n",
    "nodask['bcdev'] = -np.log(nodask['bcdev'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb(nodask, size=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb(nodask, size=15, bands=['edev', 'sdev', 'bcdev'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_slope = \"https://deafrica-data.s3.amazonaws.com/ancillary/dem-derivatives/cog_slope_africa.tif\"\n",
    "slope = rio_slurp_xarray(url_slope, gbox=ds.geobox)\n",
    "print('mean: '+str(slope.mean().values))\n",
    "print('max: '+str(slope.max().values))\n",
    "print('min: '+str(slope.min().values))\n",
    "slope.plot.hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_50 = slope>50\n",
    "_100 = slope>100\n",
    "_25 = slope>25\n",
    "_30 = slope>30\n",
    "_35 = slope>35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slope.plot(figsize=(10,10), vmax=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_25.plot(figsize=(10,10));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datacube.utils.cog import write_cog\n",
    "write_cog(_35.astype(float), 'slope_35.tif', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_35.plot(figsize=(20,20));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_30.plot(figsize=(20,20));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_50.plot(figsize=(8,8));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slope.plot.hist(figsize=(10,10), bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_of_median(da, year, sample_lat, sample_lon):\n",
    "    \"\"\"\n",
    "    da = xr.DataArray\n",
    "        Assuming an annual time-series\n",
    "    year = str\n",
    "        year of time-series in 'da'\n",
    "    sample_lat = float\n",
    "        latitude pixel coordinate\n",
    "    sample_lon = float\n",
    "        longitude pixel coordinate\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    #calculate medians for each month\n",
    "    monthly_medians = da.groupby('time.month').median()\n",
    "    \n",
    "    months = [str(i) for i in range(1,13)]\n",
    "    indexes = [i for i in range(0,12)]\n",
    "    \n",
    "    dates=[]\n",
    "    values=[]\n",
    "    for month, index in zip(months,indexes): \n",
    "        \n",
    "        #select the month of interest from da\n",
    "        m = da.sel(time=year+\"-\"+month)\n",
    "        \n",
    "        #find regions with all-NaN slices\n",
    "        mask = m.isnull().all('time')\n",
    "        \n",
    "        #calculate distance each pixel has from median\n",
    "        distance = m - monthly_medians.isel(month=index)\n",
    "        \n",
    "        #index of the absolute minimum distance\n",
    "        distance = distance.fillna(float(distance.max() + 1))\n",
    "        distance=xr.ufuncs.fabs(distance)\n",
    "        idx = distance.idxmin(dim='time', skipna=True).where(~mask)\n",
    "        value = distance.sel(time=idx, method='nearest')\n",
    "        values.append(value)\n",
    "        dates.append(idx)\n",
    "    \n",
    "    #join into dataarray along new dimension\n",
    "    dates = xr.concat(dates, \"date of median\")\n",
    "    dist_from_median = xr.concat(values, 'dist_from_monthly_median')\n",
    "    \n",
    "    #select pixel\n",
    "    dates = dates.sel(x=sample_lon, y=sample_lat, method='nearest')\n",
    "    dist_from_median = dist_from_median.sel(x=sample_lon, y=sample_lat, method='nearest')\n",
    "    \n",
    "    return dates, dist_from_median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_of_median, dist_from_median = date_of_median(ds.blue,\n",
    "                                                  sample_lon=1929690.,\n",
    "                                                  sample_lat=-4123870.,\n",
    "                                                  year='2018')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(date_of_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_from_median.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
